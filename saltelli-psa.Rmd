---
title: "Saltelli PSA for IGNITE Model"
author: "Shawn Garbett"
date: "April 3, 2019"
output:
  pdf_document: default
  html_document: default
header-includes:
- \usepackage[LGR,T1]{fontenc}
- \usepackage[utf8]{inputenc}
- \usepackage{textgreek}
- \usepackage{float}
- \usepackage[x11names,dvipsnames,table]{xcolor}
- \usepackage{boldline}
- \usepackage{multirow}
- \usepackage{colortbl}
- \usepackage{hhline}
- \usepackage{caption}
- \captionsetup[table]{labelformat=empty,textformat=empty}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tangram)

load("results-20190225.Rdata") #creation: load_results.R
x <- results[order(results$run),]

load("results-20190301.Rdata") #creation: load_results.R
y <- results[order(results$run),]

results <- cbind(x, y[,1:2])
```

```{r}
results$nmb50s1 <- 50000*(results$dQALY1 - results$dQALY0) - (results$dCOST1 - results$dCOST0)
results$nmb50s2 <- 50000*(results$dQALY2 - results$dQALY0) - (results$dCOST2 - results$dCOST0)
results$nmb50s3 <- 50000*(results$dQALY3 - results$dQALY0) - (results$dCOST3 - results$dCOST0)
results$nmb50k  <- pmax(results$nmb50s2, results$nmb50s3)

results$nmb100s1 <- 100000*(results$dQALY1 - results$dQALY0) - (results$dCOST1 - results$dCOST0)  
results$nmb100s2 <- 100000*(results$dQALY2 - results$dQALY0) - (results$dCOST2 - results$dCOST0)
results$nmb100s3 <- 100000*(results$dQALY3 - results$dQALY0) - (results$dCOST3 - results$dCOST0)
results$nmb100k  <- pmax(results$nmb100s2, results$nmb100s3)

#write.table(results$nmb50s2,  file="output/nmb50s2.csv",  row.names=FALSE, col.names=FALSE)
#write.table(results$nmb50s3,  file="output/nmb50s3.csv",  row.names=FALSE, col.names=FALSE)
#write.table(results$nmb100s2, file="output/nmb100s2.csv", row.names=FALSE, col.names=FALSE)
#write.table(results$nmb100s3, file="output/nmb100s3.csv", row.names=FALSE, col.names=FALSE)
#write.table(results$nmb50k,   file="output/nmb50k.csv",   row.names=FALSE, col.names=FALSE)
#write.table(results$nmb100k,  file="output/nmb100k.csv",  row.names=FALSE, col.names=FALSE)

```

# PSA

This report documents the results of using Saltelli's method of probability sensitivity analysis on the IGNITE model. 

The method chosen uses a low discrepency sequence sample of the defined space and explores permuatations of the samples in a methodical manner in such a way to maximize information returned about the probability sensitivity of the model. For this analysis we chose an N=100 values in that the primary sample is 100 points from a Halton sequence that draws 2 uncorrelated positions as defined by the parameter space. In this instance the parameter space has 48 variables. Thus for each of the 100 draws it draws from a 96 dimensional space. The secondary 48 is shuffled to destroy any residual correlation from the Halton draw. Then each parameter is permuted across these pairs in the space. This results in 9800 defined models runs.

For each run, we evaluate 3 scenarios for cost and quality. These are the 0, 1, and 3 scenarios of the IGNITE project.

## Scenarios

* Scenario 0. (Reference) Single drug start on Clopidogrel no testing.
* Scenario 1. Single drug start on Tricagrelor no testing.
* Scenario 3. Genotype and switch based on test.

## Ranges

```{r ranges, results="asis", echo=FALSE}
ranges <- read.csv("psa-ranges2.csv")
ranges$Variable <- as.character(ranges$Variable)
#ranges[46,"Variable"] <- "Mont"
ranges$Low <- render_f(ranges$Low, 4)
ranges$High <- render_f(ranges$High, 4)
tangram(ranges,
        as.character=TRUE,
        style="nejm",
        id="ranges",
        caption="Parameter Ranges for PSA",
        pct_width=0.8)

params <- read.csv("sample.txt", header=FALSE)
colnames(params) <- ranges$Variable

# Throw away failed runs for scenario 3
params  <- params[results$dQALY3 > 0.8, ]
results <- results[results$dQALY3 > 0.8, ]
```
## Raw Results

Given that the sample space is carefully designed and has a very specific structure to maximize information returned to the PSA, the raw data is not particularly useful. It's included here as an exploratory measure to show that runs did have variance and show how their structures varied.

```{r, echo=FALSE}
par(mfrow=c(2,2))

myplot <- function(x, y, label)
   plot(results[,x], results[,y],
         pch=16,
         xlab="dQALY", ylab="dCOST",
         main=label,
         cex=0.5, col=rgb(0,0,0,0.2)
         ,xlim=c(0.89, 0.96)
         ,ylim=c(5000, 14000)
        )

myplot(1, 2, "Scenario 0")
myplot(8, 9, "Scenario 1")
myplot(5, 6, "Scenario 3")
#hist(results$nmb100k, main="Net Monetary Benefit", sub="WTP=$100k", xlab="Dollars ($)", freq=FALSE)
```

# Tornado Plots

These are made with the standard linear regression across factors.

```{r}

library(scales)
library(ggplot2)
TornadoOpt <-function(Parms,
                      Outcomes,
                      txtsize=6,
                      opt=NULL,
                      title="Tornado Diagram",
                      select=NULL)
{
  # Grouped Bar Plot
  # Determine the overall optimal strategy
  if(is.null(opt)) opt<-which.max(colMeans(Outcomes))
  # calculate min and max vectors of the parameters (e.g., lower 2.5% and 97.5%)
  X <- as.matrix(Parms)
  y <- as.matrix(Outcomes[,opt])
  ymean <- mean(y)
  n <- nrow(Parms)
  nParams <- ncol(Parms)
  #paramNames <- Names[seq(8,7+nParams)]
  paramNames <- colnames(Parms)
  Parms.sorted <- apply(Parms,2,sort,decreasing=F)#Sort in increasing order each column of Parms
  lb <- 2.5
  ub <- 97.5 
  Xmean <- rep(1,nParams) %*% t(colMeans(X))
  XMin <- Xmean
  XMax <- Xmean
  paramMin <- as.vector(Parms.sorted[round(lb*n/100),])
  paramMax <- as.vector(Parms.sorted[round(ub*n/100),])
  paramNames2 <- paramNames # paste(paramNames, "[", round(paramMin,2), ",", round(paramMax,2), "]")
  
  diag(XMin) <- paramMin
  diag(XMax) <- paramMax
  
  XMin <- cbind(1, XMin)
  XMax <- cbind(1, XMax)
  
  X <- cbind(1,X)
  B <- solve(t(X) %*% X) %*% t(X) %*% y
  yMin <- XMin %*% B - ymean
  yMax <- XMax %*% B - ymean
  ySize <- abs(yMax - yMin) 
  
  rankY<- order(ySize)
  xmin <- min(c(yMin, yMax)) + ymean
  xmax <- max(c(yMin, yMax)) + ymean
  
  Tor <- data.frame(
    Parameter=c(paramNames2[rankY],paramNames2[rankY]),  
    Level=c(rep("Low",nParams),rep("High",nParams)),
    value=ymean+c(yMin[rankY],yMax[rankY]),
    sort=seq(1,nParams)
  )
  
  if(!is.null(select)) Tor <- subset(Tor, Parameter %in% select)
  
  #re-order the levels in the order of appearance in the data.frame
  Tor$Parameter2 <- factor(Tor$Parameter, unique(as.character(Tor$Parameter)))
  #Define offset as a new axis transformation. Source: http://blog.ggplot2.org/post/25938265813/defining-a-new-transformation-for-ggplot2-scales  
  offset_trans <- function(offset=0) {
    trans_new(paste0("offset-", format(offset)), function(x) x-offset, function(x) x+offset)
  }
  #Plot the Tornado diagram.
  ggplot(Tor[Tor$Level=="Low",], aes(x=Parameter2,y=value, fill=Level)) +
    geom_bar(stat="identity") +
    ggtitle(title)+
    scale_fill_discrete("Parameter Limit: ", l=50)+
    scale_y_continuous(name="Difference Net Monetary Benefit",trans=offset_trans(offset=ymean)) +
    scale_x_discrete(name="Parameter") +
    geom_bar(data=Tor[Tor$Level=="High",], aes(x=Parameter2,y=value, fill=Level), stat="identity") +
    geom_hline(yintercept = ymean, linetype = "dotted", size=0.5) +
    theme_bw()+
    theme(legend.position="bottom",legend.title=element_text(size = txtsize,angle = 0, hjust = 1),
          legend.key = element_rect(colour = "black"),
          legend.text = element_text(size = txtsize),
          title = element_text(face="bold", size=15),
          axis.title.x = element_text(face="bold", size=txtsize),
          axis.title.y = element_text(face="bold", size=txtsize),
          axis.text.y = element_text(size=txtsize),
          axis.text.x = element_text(size=txtsize),
          axis.ticks.y = element_blank())+
    coord_flip()  
}

# Have to include an additional result then select using opt. Wish this wasn't the case
TornadoOpt(as.matrix(params), as.matrix(cbind(results$nmb100s1, results$nmb100s2)), opt=1, title="Sensitivity Scenario 1 WIP 100k")

TornadoOpt(as.matrix(params), as.matrix(cbind(results$nmb100s2, results$nmb100s3)), opt=2, title="Sensitivity Scenario 3 WIP 100k")
```

# Sensitivity Scenario 1 Compared to 0 (Top 15)

```{r}
pdf("PSA-Scenario1-top15.pdf")
TornadoOpt(as.matrix(params), as.matrix(cbind(results$nmb100s1, results$nmb100s2)), opt=1,
           title="", #"Sensitivity Scenario 1 (Top 15)",
           txtsize = 12,
           select=c(
             "1y risk MI Non-LOF Ticagrelor",
             "1y risk MI LOF Clopidogrel",
             "Monthly Cost of Ticagrelor",
             "30d risk MI Non-LOF Ticagrelor",
             "Case Fatality LOF Clopidogrel",
             "30d risk ST Non-LOF Ticagrelor",
             "30d risk Stroke Non-LOF Ticagrelor",
             "30d risk MI LOF Clopidogrel",
             "1y risk MI Non-LOF Clopidogrel",
             "Case Fatality Non-LOF Ticagrelor",
             "1y risk ST LOF Ticagrelor",
             "30d risk ST LOF Clopidogrel",
             "1y risk MI LOF Ticagrelor",
             "Case Fatality Non-LOF Clopidogrel",
             "30d risk Stroke Non-LOF Clopidogrel"
             ) )
dev.off()
```

## Sensitivity Scenario 3 compared to 0 (Top 15)

```{r}
pdf("PSA-Scenario3-top15.pdf")
TornadoOpt(as.matrix(params), as.matrix(cbind(results$nmb100s3, results$nmb100s2)), opt=1,
           title="", #"Sensitivity Scenario 3 (Top 15)",
           txtsize = 12,
           select=c(
             "1y risk MI LOF Clopidogrel",
             "Case Fatality LOF Clopidogrel",
             "30d risk MI LOF Clopidogrel",
             "30d risk Stroke LOF Clopidogrel",
             "30d risk ST LOF Clopidogrel",
             "1y risk MI LOF Ticagrelor",
             "1y risk ST LOF Ticagrelor",
             "30d risk MI LOF Ticagrelor",
             "Monthly Cost of Ticagrelor",
             "30d risk Stroke LOF Ticagrelor",
             "Case Fatality LOF Ticagrelor",
             "30d risk ST LOF Ticagrelor",
             "Monthly Cost of Clopidogrel",
             "Relative risk Extracranial Bleed Ticagrelor",
             "Cost of Single Test"
             ) )
dev.off()
```


## Acceptability

```{r}
percent <- function(name) paste0(round(100*sum(results[,name]>0)/length(results[,name]), 2), "%")
```

* `r percent("nmb100s1")` of scenario 1 net monetary benefits are greater than zero at a williness to pay threshold of $100k.
* `r percent("nmb100s3")` of scenario 3 net monetary benefits are greater than zero at a williness to pay threshold of $100k.
* `r percent("nmb50s1")` of scenario 1 net monetary benefits are greater than zero at a williness to pay threshold of $50k.
* `r percent("nmb50s3")` of scenario 3 net monetary benefits are greater than zero at a williness to pay threshold of $50k.


```{r, warnings=FALSE, comment="", echo=FALSE, message=FALSE}
library(dampack)

wtp <- seq(0, 2e5, by=1e4)
postscript("ceaf.pdf")
ceaf(v.wtp = wtp, strategies = c(0,1,3),
     m.e = results[,c("dQALY0", "dQALY1", "dQALY3")],
     m.c = results[,c("dCOST0", "dCOST1", "dCOST3")])$gg.ceaf +
scale_x_continuous(breaks=number_ticks(10))
dev.off()
```

## Delta Plots

```{r}
plot(results$dQALY1 - results$dQALY0, 
     results$dCOST1 - results$dCOST0,
     main="Scenario 1", sub="Cost Effectiveness compared to reference",
     xlab="Delta dQALY",
     ylab="Delta dCOST",
     col=rgb(0,0,0,0.25),
     pch=16)
abline(a=0, b=100000, col='red')
abline(a=0, b=50000, col='blue')
legend(-0.025, 2000, c("100k", "50k"), col=c("red", "blue"), lty=1)

plot(results$dQALY3 - results$dQALY0, 
     results$dCOST3 - results$dCOST0,
     main="Scenario 3", sub="Cost Effectiveness compared to reference",
     xlab="Delta dQALY",
     ylab="Delta dCOST",
     col=rgb(0,0,0,0.25),
     pch=16)
abline(a=0, b=100000, col='red')
abline(a=0, b=50000, col='blue')
legend(0.0225, 1500, c("100k", "50k"), col=c("red", "blue"), lty=1, bg="white")
```


